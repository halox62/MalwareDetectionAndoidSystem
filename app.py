from flask import Flask, render_template, request, jsonify, send_file
from flask_socketio import SocketIO, emit
import tensorflow as tf
from tensorflow import keras as k
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import lime
from lime.lime_tabular import LimeTabularExplainer
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns


app = Flask(__name__)
socketio = SocketIO(app)

# funzione per allenare il modello
def train_model(X_train, y_train,epoche):
    model = k.Sequential([
        k.layers.Dense(16, activation=k.activations.relu, kernel_regularizer=k.regularizers.l2(0.001)),
        k.layers.Dropout(0.5),
        k.layers.Dense(16, activation=k.activations.relu, kernel_regularizer=k.regularizers.l2(0.001)),
        k.layers.Dropout(0.5),
        k.layers.Dense(1, activation=k.activations.sigmoid)
    ])
    model.build(input_shape=(None, X_train.shape[1]))

    model.compile(optimizer=k.optimizers.legacy.Adam(), loss=k.losses.binary_crossentropy, metrics=['accuracy'])

    class TrainingCallback(tf.keras.callbacks.Callback):
        def on_epoch_end(self, epoch, logs=None):
            log_message = f"Epoch {epoch + 1}/{self.params['epochs']} - loss: {logs['loss']:.4f} - accuracy: {logs['accuracy']:.4f} - val_loss: {logs['val_loss']:.4f} - val_accuracy: {logs['val_accuracy']:.4f}"
            socketio.emit('training_log', {'message': log_message})

    history = model.fit(X_train, y_train, epochs=epoche, batch_size=32, validation_split=0.2, callbacks=[TrainingCallback()])
    model.summary(print_fn=lambda x: socketio.emit('training_log', {'message': x}))
    model.save('trained_model.h5')
    return model


def evaluate_model(model, X_test, y_test):
    test_loss, test_accuracy = model.evaluate(X_test, y_test)
    return test_accuracy


def make_predictions(model, X):
    y_pred = model.predict(X)
    threshold = 0.5
    binary_predictions = (y_pred > threshold).astype(int)
    return binary_predictions

# funzione per caricare il modello
def load_model(file_path):
    return k.models.load_model(file_path)

def train_and_evaluate(X_train, y_train, X_test, y_test,epoche):
    model = train_model(X_train, y_train,epoche)
    accuracy = evaluate_model(model, X_test, y_test)
    return model, accuracy

def evaluate_pretrained_model(X_test, y_test):
    model_path = "trained_model.h5"  
    model = load_model(model_path)
    accuracy = evaluate_model(model, X_test, y_test)
    return model, accuracy


def explain_with_lime(model, X_train, X_test, feature_names, instance_index):
    def predict_proba(x):
        y_pred = model.predict(x)
        if y_pred.shape[1] == 1:
            y_pred = np.hstack([1 - y_pred, y_pred])
        return y_pred

    try:

        # Normalizza i dati
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)

         # Verifica se l'indice è valido
        if instance_index < 0 or instance_index >= len(X_test_scaled):
            raise IndexError("Indice non valido")


        # Crea l'esploratore LIME
        explainer = LimeTabularExplainer(
            training_data= X_train_scaled,
            feature_names=feature_names,
            class_names=['No Malware', 'Malware'],
            mode='classification',
            discretize_continuous=False,
            kernel_width=8.0
        )        
        
        # Istanza da spiegare
        instance = X_test_scaled[instance_index]

        

        # Genera la spiegazione
        exp = explainer.explain_instance(
            data_row=instance,
            predict_fn=predict_proba,
            num_features=540,
            num_samples=10000
        )

        # Recupera la probabilità dalla spiegazione
        local_pred_prob = exp.local_pred[0]

        # Imposta la soglia
        threshold = 0.5

        lime_exp = {
            'local_pred': exp.local_pred.tolist(),
            'score': exp.score,
            'as_list': [list(item) for item in exp.as_list() if item[1] != 0],  # Escludi le feature con peso zero
            'feature_names': feature_names,
            'class_names': ['No Malware', 'Malware'],
            'predicted_class': 'Malware' if local_pred_prob > threshold else 'No Malware'
        }

        return lime_exp
    
    except IndexError:
        return {'error': 'Indice non valido'}
    

# Load data from CSV files
df_legittime = pd.read_csv("real_legitimate_v1.csv")
df_malevoli = pd.read_csv("real_malware_v1.csv")

df_legittime_emu = pd.read_csv("emu_legitimate_v1.csv")
df_malevoli_emu = pd.read_csv("emu_malware_v1.csv")

df = pd.concat([df_legittime, df_malevoli], ignore_index=True)
df = df.fillna(0)

df_emu = pd.concat([df_legittime_emu, df_malevoli_emu], ignore_index=True)
df_emu = df_emu.fillna(0)

X = df.drop(columns=["Malware","Package","sha256","EarliestModDate","HighestModDate","MalFamily"]).values
X_emu = df_emu.drop(columns=["Malware","Package","sha256","FirstModDate","LastModDate","MalFamily"]).values

y = df["Malware"].values
y_emu = df_emu["Malware"].values

scaler = StandardScaler()
X = scaler.fit_transform(X)
X_emu = scaler.fit_transform(X_emu)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
X_train_emu, X_test_emu, y_train_emu, y_test_emu = train_test_split(X_emu, y_emu, test_size=0.2, random_state=42)

feature_names = df.drop(columns=["Malware","Package","sha256","EarliestModDate","HighestModDate","MalFamily"]).columns.tolist()


@app.route('/')
def index():
    return render_template('interfaceApp.html')

@app.route('/train', methods=['POST'])
def train():
    data_type = request.form['data_type']
    epoche=request.form['user_valueTrain']
    if not epoche.isdigit() or int(epoche) <= 0:
        return jsonify({'error': 'Invalid epoch value'}), 400
    if data_type == 'original':
        model, accuracy = train_and_evaluate(X_train, y_train, X_test, y_test,int(epoche))
    elif data_type == 'emulated':
        model, accuracy = train_and_evaluate(X_train_emu, y_train_emu, X_test_emu, y_test_emu,int(epoche))
    else:
        return jsonify({'error': 'Invalid data type'}), 400
    return jsonify({'accuracy': accuracy})

@app.route('/evaluate', methods=['POST'])
def evaluate():
    data_type = request.form['data_type']
    if data_type == 'original':
        model, accuracy = evaluate_pretrained_model(X_test, y_test)
    elif data_type == 'emulated':
        model, accuracy = evaluate_pretrained_model(X_test_emu, y_test_emu)
    else:
        return jsonify({'error': 'Invalid data type'}), 400
    return jsonify({'accuracy': accuracy})


@app.route('/lime' , methods=['POST'])
def lime():
    user_value = request.form.get('user_value')
    if not user_value.isdigit():
          return jsonify({'error': 'Indice non valido'}), 400
    model_path = "trained_model.h5" 
    model = load_model(model_path)
    lime_explanation = explain_with_lime(model, X_train, X_test, feature_names, instance_index=int(user_value))
    return jsonify({'lime_explanation': lime_explanation})

@app.route('/classification' , methods=['POST'])
def classification():
    model_path = "trained_model.h5" 
    model = load_model(model_path)
    y_pred = make_predictions(model, X_test);
    report = classification_report(y_test, y_pred, output_dict=True)
    return jsonify({'classification_report': report})

@app.route('/confusion_matrix_emulated', methods=['GET'])
def confusion_matrix_emulated_api():
    model_path = "trained_model.h5"
    model = load_model(model_path)
    y_pred = model.predict(X_test_emu)
    
    y_pred_classes = (y_pred > 0.5).astype(int)  
    cm = confusion_matrix(y_test_emu, y_pred_classes)
    
    cm_json = {
        "confusion_matrix": cm.tolist(), 
        "labels": np.unique(y_test).tolist() 
    }
    
    return jsonify(cm_json)

@app.route('/confusion_matrix_real', methods=['GET'])
def confusion_matrix_real_api():
    model_path = "trained_model.h5"
    model = load_model(model_path)
    y_pred = model.predict(X_test)
    
    y_pred_classes = (y_pred > 0.5).astype(int)  
    cm = confusion_matrix(y_test, y_pred_classes)
    
    cm_json = {
        "confusion_matrix": cm.tolist(), 
        "labels": np.unique(y_test).tolist() 
    }
    
    return jsonify(cm_json)

if __name__ == "__main__":
    socketio.run(app, debug=True)